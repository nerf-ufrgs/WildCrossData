[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Quality Checks",
    "section": "",
    "text": "0.1 Welcome\nThis book documents the data quality checks performed on the camera trap data. Each chapter describes a specific check and its implementation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Datapaper WildCrossData Latin America</span>"
    ]
  },
  {
    "objectID": "index.html#chapters",
    "href": "index.html#chapters",
    "title": "Data Quality Checks",
    "section": "0.2 Chapters",
    "text": "0.2 Chapters\n\nColumn Consistency - Checks for consistency in column types across spreadsheets.\nBlank Cells - Identifies blank cells and sheets in the data.\nSpecies Validity - Validates species names using the Global Names Verifier API.\nStructure Checks - Verifies consistency between camera trap and structure data\nCamera ID Verification - Ensures camera IDs are properly linked across datasets.\nCamera Date Checks - Checks several possibilities for anomalous dates.\nCamera ID Duplicated on Structure - Tests if there is a duplicated camera IDs for a given structure.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Datapaper WildCrossData Latin America</span>"
    ]
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Data Quality Checks",
    "section": "0.3 About",
    "text": "0.3 About\nThis book is part of the data quality assurance process for the camera trap dataset. Each check is implemented in R and documented using Quarto.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Datapaper WildCrossData Latin America</span>"
    ]
  },
  {
    "objectID": "Quarto/00_PRESENTATION_FUNCTIONS.html",
    "href": "Quarto/00_PRESENTATION_FUNCTIONS.html",
    "title": "2  Step 0 - Creating customized functions",
    "section": "",
    "text": "3 Presentation\nBlabla",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Step 0 - Creating customized functions</span>"
    ]
  },
  {
    "objectID": "Quarto/00_PRESENTATION_FUNCTIONS.html#read_sheet",
    "href": "Quarto/00_PRESENTATION_FUNCTIONS.html#read_sheet",
    "title": "2  Step 0 - Creating customized functions",
    "section": "4.1 read_sheet",
    "text": "4.1 read_sheet\nOne the first steps of our datapaper was to create functions that are common to several other checks that we will perform.\nThe primary function concerns to reading the Excel files and their spreadsheets containing the data. Since some other checks didn’t need the results of the reading but only the names of the datasets and their paths, we created a function encompassing these issues. The function is called read_sheet.\n\n\nCode\nread_sheet &lt;- function(\n  path = \"Example\",\n  sheet = NULL,\n  na = \"\",\n  results = TRUE\n) {\n  excel &lt;- list.files(\n    path = path,\n    pattern = \"^\\\\w.+xlsx$\",\n    full.names = TRUE,\n    recursive = TRUE\n  )\n\n  names &lt;- excel |&gt;\n    stringr::str_split(\"/|\\\\.\") |&gt;\n    purrr::map_vec(2)\n\n  load &lt;- excel |&gt;\n    purrr::set_names(names)\n\n  if (!results) {\n    return(load)\n  }\n\n  column_types &lt;- set_column_types(sheet = sheet)\n\n  result &lt;- load |&gt;\n    purrr::map(function(file) {\n      df &lt;- withCallingHandlers(\n        readxl::read_xlsx(\n          path = file,\n          sheet = sheet,\n          na = na,\n          col_names = TRUE,\n          col_types = column_types\n        )\n      ) |&gt;\n        janitor::remove_empty(\"rows\")\n\n      names(df) &lt;- df |&gt;\n        janitor::clean_names() |&gt;\n        colnames() |&gt;\n        stringr::str_to_sentence()\n\n      return(df)\n    })\n\n  return(result)\n}\n\n\nThe function has four arguments:\n\npath: the pattern was set to “Excel” as this is the folder where our files are stored.\nsheet: we put as NULL because we may not want to have the full results, therefore, there is no need to read the spreadsheets.\nna: to define what are the options to read NA. Default ““.\nresults: we may not want the results but only the paths for the datasets in customized functions (see Column Consistency).\n\nTo read the spreadsheets we need to list the files on the folder, by specifying which one is an Excel file. We ask R to return the full names, which include the full path of the file. For the sake of organization we also named the previous vector with the paths of the spreadsheets with the respective names of their main authors. Now we set the names of the paths with the author’s names extracted in last step.\nFirstly, we retrieve the full path of any .xlsx file found inside the “Excel” folder. The second step consists on splitting the full path into pieces and plucking the second element, as it represents the name of the dataset. Following, we name every full path with the name of the dataset. If we are reading the Excel files with a customized function, we stop here. If not, we read every Excel file of the list considering the sheet informed. The results comprise the name of the columns in a specific format, which is initiated by a capital letter followed by lowercase letters with the underscore separator for words.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Step 0 - Creating customized functions</span>"
    ]
  },
  {
    "objectID": "Quarto/00_PRESENTATION_FUNCTIONS.html#unique_id",
    "href": "Quarto/00_PRESENTATION_FUNCTIONS.html#unique_id",
    "title": "2  Step 0 - Creating customized functions",
    "section": "4.2 unique_id",
    "text": "4.2 unique_id\nThe function takes two arguments:\n\nx: a data frame from the Camera_trap sheet.\n\nsep: a string (default \"_\") used to separate the original Camera_id from an appended letter when duplicates are found.\n\nInternally, it adds a helper column rowid with to preserve the original row order, then groups the data by Structure_id and Camera_id and counts how many times each pair appears into a column called double. Within each group it saves the original Camera_id as Camera_id_orig, assigns a sequential index Dup_id and constructs Dup_form_name: if double equals 1 it keeps the original Camera_id, otherwise it appends the separator and a letter from LETTERS based on Dup_id. After ungrouping, it selects the helper columns (rowid, Camera_id_orig, Dup_form_name, double) and left-joins them back onto the original data by rowid, then updates Camera_id to Dup_form_name when present, relocates Camera_id_orig immediately after Camera_id, and drops the temporary columns.\nThe practical effect is to ensure that within each Structure_id–Camera_id group any repeated camera IDs become unique by appending letters, while preserving the original ID in Camera_id_orig and returning the full updated data frame.\n\n\nCode\nunique_id &lt;- function(x, sep = \"_\") {\n  x_with_id &lt;- x |&gt;\n    tibble::rowid_to_column()\n\n  x_with_id |&gt;\n    dplyr::group_by(Structure_id, Camera_id) |&gt;\n    dplyr::add_count(Structure_id, Camera_id, name = \"double\") |&gt;\n    dplyr::mutate(\n      Camera_id_orig = Camera_id,\n      Dup_id = dplyr::row_number(Camera_id),\n      Dup_form_name = dplyr::if_else(\n        condition = double == 1,\n        true = Camera_id,\n        false = stringr::str_c(Camera_id, sep, LETTERS[Dup_id])\n      )\n    ) |&gt;\n    dplyr::ungroup() |&gt;\n    dplyr::select(rowid, Camera_id_orig, Dup_form_name, double) |&gt;\n    dplyr::left_join(x_with_id, ., by = \"rowid\") |&gt;\n    dplyr::mutate(\n      Camera_id = dplyr::if_else(\n        !is.na(Dup_form_name),\n        Dup_form_name,\n        Camera_id\n      )\n    ) |&gt;\n    dplyr::relocate(Camera_id_orig, .after = Camera_id) |&gt;\n    dplyr::select(-Dup_form_name, -rowid)\n}",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Step 0 - Creating customized functions</span>"
    ]
  },
  {
    "objectID": "Quarto/00_PRESENTATION_FUNCTIONS.html#dttm_update",
    "href": "Quarto/00_PRESENTATION_FUNCTIONS.html#dttm_update",
    "title": "2  Step 0 - Creating customized functions",
    "section": "4.3 dttm_update",
    "text": "4.3 dttm_update\nThe function takes three arguments:\n\nx: a data frame containing date and time columns.\ndate_col: the name (string) of the column that stores the date part.\ntime_col: the name (string) of the column that stores the time part.\n\nInternally, we update the original date column using lubridate:::update_datetime(), combining the existing date with hours, minutes, and seconds extracted from the time column via lubridate::hour(), lubridate::minute(), and lubridate::second().\nThe practical effect is to merge the date information from one column with the time information from another, producing a complete datetime object in the specified date column and returning the updated data frame.\n\n\nCode\ndttm_update &lt;- function(x, date_col, time_col) {\n  date_sym &lt;- rlang::sym(date_col)\n  time_sym &lt;- rlang::sym(time_col)\n\n  x |&gt;\n    dplyr::mutate(\n      !!date_sym := lubridate:::update_datetime(\n        !!date_sym,\n        hour = lubridate::hour(!!time_sym),\n        minute = lubridate::minute(!!time_sym),\n        second = lubridate::second(!!time_sym)\n      )\n    )\n}",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Step 0 - Creating customized functions</span>"
    ]
  },
  {
    "objectID": "Quarto/01_COLUMN_CONSISTENCY.html",
    "href": "Quarto/01_COLUMN_CONSISTENCY.html",
    "title": "3  Step 1 - Check Column Consistency",
    "section": "",
    "text": "4 Problem description\nThe idea behind this was simply to bind rows of every spreadsheet and check for warnings and errors. If column types were different errors had to be risen and formats would be subject of warnings.\nThe first step of checking the spreadsheets consisted in trying to read all of them and binding their rows. By doing this, if the column type was not the same, we then had to set the columns with the same type. Also, by reading each spreadsheet, read_excel may warns us if something is wrong.\n\n\n5 Problem solving\nWe defined for each column over the 5 spreadsheets which type all of them were. We populated a table directly in Excel and then we read using the following commands:\n\n\nCode\ncol_types &lt;- list()\n\npath &lt;- \"support/column_types.xlsx\"\n\nsheet_names &lt;- readxl::excel_sheets(path)\n\nfor (i in 1:length(sheet_names)) {\n  col_types[[sheet_names[i]]] &lt;- readxl::read_excel(path = path, sheet = i)\n}\n\n# Showing an example of the output\ncol_types[1]\n\n\n$Underpasses\n# A tibble: 17 × 2\n   Column              Type   \n   &lt;chr&gt;               &lt;chr&gt;  \n 1 Infrastructure_type text   \n 2 Structure_ID        text   \n 3 Structure_type      text   \n 4 Structure_cell      text   \n 5 Structure_shape     text   \n 6 Structure_photo     text   \n 7 Structure_age       numeric\n 8 Structure_height    numeric\n 9 Structure_length    numeric\n10 Structure_width     numeric\n11 Waterbody_width     numeric\n12 Latitude            numeric\n13 Longitude           numeric\n14 UTM Zone            text   \n15 X (Easting)         numeric\n16 Y (Northing)        numeric\n17 Datum               text   \n\n\nThe following process has to be repeated for all the spreadsheets, however here we illustrate using the “Underpasses” spreadsheet. In order to collect the messages provided by R we adapted the read_excel function with a purrr::quietly function, that is more appropriate to show warnings and messages for each file/author. We enchain the customized read_sheet function that provides the full paths of all .xlsx files available to the purrr::quietly function.\nIn the sequence, we are able to collect the warnings (in this case, under_warns), check and correct them directly on the Excel files. The majority of the errors are misspelled text, decimal markers, date and time separators and so on…\nAfter we zeroing the warnings, we are able to check if R successfully bind the rows from each author. If no warnings or errors are raised, it means that we reached our goal.\n\n\nCode\n#Underpasses ----\nsource(\"R/FUNCTIONS.R\")\n\nunder_q &lt;- purrr::quietly(function(file) {\n  readxl::read_excel(\n    file,\n    col_types = col_types[[\"Underpasses\"]]$Type,\n    sheet = \"Underpasses\",\n    na = c(\"NA\", \"na\"),\n    col_names = TRUE\n  ) |&gt;\n    janitor::remove_empty(\"rows\")\n})\n\nunder_all_outputs &lt;- read_sheet(path = \"Example\", results = FALSE) |&gt;\n  purrr::map(under_q)\n\nunder_warns &lt;- under_all_outputs |&gt;\n  purrr::map(\\(x) purrr::pluck(x, \"warnings\")) |&gt;\n  purrr::compact()\n\nunder_results &lt;- under_all_outputs |&gt;\n  purrr::map(\\(x) purrr::pluck(x, \"result\")) |&gt;\n  dplyr::bind_rows(.id = \"Dataset\")\n\nunder_results |&gt;\n  print(n = 10)\n\n\n# A tibble: 95 × 18\n   Dataset  Infrastructure_type Structure_ID    Structure_type    Structure_cell\n   &lt;chr&gt;    &lt;chr&gt;               &lt;chr&gt;           &lt;chr&gt;             &lt;chr&gt;         \n 1 Example1 Rodovia             P1 (iguaçu)     Ponte             &lt;NA&gt;          \n 2 Example1 Rodovia             BC1 (galeria)   Bueiro de concre… &lt;NA&gt;          \n 3 Example1 Rodovia             P2 (mauricio)   Ponte             &lt;NA&gt;          \n 4 Example1 Rodovia             BC2 (drenagem)  Bueiro de concre… &lt;NA&gt;          \n 5 Example1 Rodovia             BCS1            Bueiro com plata… &lt;NA&gt;          \n 6 Example1 Rodovia             P3 (varzea)     Ponte             &lt;NA&gt;          \n 7 Example1 Rodovia             P4 (fazenda)    Ponte             &lt;NA&gt;          \n 8 Example1 Rodovia             P5 (sapezal)    Ponte             &lt;NA&gt;          \n 9 Example1 Rodovia             P6 (passa três) Ponte             &lt;NA&gt;          \n10 Example1 Rodovia             P7 (lourenço)   Ponte             &lt;NA&gt;          \n# ℹ 85 more rows\n# ℹ 13 more variables: Structure_shape &lt;chr&gt;, Structure_photo &lt;chr&gt;,\n#   Structure_age &lt;dbl&gt;, Structure_height &lt;dbl&gt;, Structure_length &lt;dbl&gt;,\n#   Structure_width &lt;dbl&gt;, Waterbody_width &lt;dbl&gt;, Latitude &lt;dbl&gt;,\n#   Longitude &lt;dbl&gt;, `UTM Zone` &lt;chr&gt;, `X (Easting)` &lt;dbl&gt;,\n#   `Y (Northing)` &lt;dbl&gt;, Datum &lt;chr&gt;",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Step 1 - Check Column Consistency</span>"
    ]
  },
  {
    "objectID": "Quarto/02_BLANK_CELLS.html",
    "href": "Quarto/02_BLANK_CELLS.html",
    "title": "4  Step 2 - Check Blank Cells",
    "section": "",
    "text": "5 Problem description\nInitially, we asked for all researchers to completely fill all sheets and cells over the file submitted. This was required for us to be sure that the authors didn’t forget to fill out some information. We asked that all cells without information should be filled with NA.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Step 2 - Check Blank Cells</span>"
    ]
  },
  {
    "objectID": "Quarto/02_BLANK_CELLS.html#common-steps",
    "href": "Quarto/02_BLANK_CELLS.html#common-steps",
    "title": "4  Step 2 - Check Blank Cells",
    "section": "6.1 Common steps",
    "text": "6.1 Common steps\nTo solve this issue, we first load our common function file:\n\n\nCode\nsource(\"R/FUNCTIONS.R\")\n\n\nTo read the spreadsheets we run the read_sheet function that is included on our functions file. However, before doing it, we did two preliminary steps: 1) created a blank list object called list_sheet_dataset and 2) a vector object sheets with the name of all the spreadsheets that must be read sometime in our evaluations.\n\n\nCode\nlist_sheet_dataset &lt;- list()\n\nspreadsheets &lt;- c(\n  \"Underpasses\",\n  \"Overpasses\",\n  \"Fencing\",\n  \"Camera_trap\",\n  \"Species_records_camera\",\n  \"Author_data\"\n)\n\n# we read every sheet for every dataset\nfor (spreadsheet in spreadsheets) {\n  message(stringr::str_glue(\"\\nStarting sheet {spreadsheet}\\n\"))\n  list_sheet_dataset[[spreadsheet]] &lt;- read_sheet(\n    path = \"Example\",\n    sheet = spreadsheet\n  )\n\n  message(stringr::str_glue(\"\\nFinalizing sheet {spreadsheet}\\n\"))\n}",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Step 2 - Check Blank Cells</span>"
    ]
  },
  {
    "objectID": "Quarto/02_BLANK_CELLS.html#checking-spreadsheets-name-consistency",
    "href": "Quarto/02_BLANK_CELLS.html#checking-spreadsheets-name-consistency",
    "title": "4  Step 2 - Check Blank Cells",
    "section": "6.2 Checking spreadsheets name consistency",
    "text": "6.2 Checking spreadsheets name consistency\nJust to be completely sure that all datasets and their respective spreadsheets had been read, we proceed counting the number of datasets and comparing then to the number of datasets found and stored in list_sheet_dataset.\n\n\nCode\nnumber_of_dataset &lt;- list.files(path = \"Example\") |&gt;\n  length()\n\nlist_sheet_dataset |&gt;\n  purrr::map(~ length(.x) == number_of_dataset)\n\n\n$Underpasses\n[1] TRUE\n\n$Overpasses\n[1] TRUE\n\n$Fencing\n[1] TRUE\n\n$Camera_trap\n[1] TRUE\n\n$Species_records_camera\n[1] TRUE\n\n$Author_data\n[1] TRUE",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Step 2 - Check Blank Cells</span>"
    ]
  },
  {
    "objectID": "Quarto/02_BLANK_CELLS.html#finding-all-blank-sheets",
    "href": "Quarto/02_BLANK_CELLS.html#finding-all-blank-sheets",
    "title": "4  Step 2 - Check Blank Cells",
    "section": "6.3 Finding all blank sheets",
    "text": "6.3 Finding all blank sheets\nWe are going to reduce the number of levels of list_sheet_dataset from 2 to 1 using the list_flatten function. In this way we will have a large single list which their names will be a combination of the name of the spreadsheet plus the dataset.\nWe iterate each data frame and create a numerical and incremental id to the sheet. We create another index column called row that just matches the row that we see in Excel. Then, we create a column that checks if the sum of the indexes is equal to 0. If this is the case (“Uh oh!”), we only have the row that we manually inserted, meaning that the full sheet was not filled - ERROR! The result of this analysis is a vector with the name of the spreadsheets and their respective datasets.\n\n\nCode\nlist_sheet_dataset |&gt;\n  purrr::list_flatten() |&gt;\n  purrr::map(\n    ~ tibble::rowid_to_column(.x, \"id\") |&gt;\n      dplyr::add_row(id = 0) |&gt;\n      dplyr::mutate(\n        row = id + 1,\n        in_or_out = dplyr::if_else(sum(id) == 0, \"Uh oh!\", \"OK\")\n      ) |&gt;\n      dplyr::filter(in_or_out == \"Uh oh!\") |&gt;\n      dplyr::select(row)\n  ) |&gt;\n  purrr::keep(~ nrow(.x) &gt;= 1) |&gt;\n  names()\n\n\ncharacter(0)",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Step 2 - Check Blank Cells</span>"
    ]
  },
  {
    "objectID": "Quarto/02_BLANK_CELLS.html#finding-sparse-blank-cells",
    "href": "Quarto/02_BLANK_CELLS.html#finding-sparse-blank-cells",
    "title": "4  Step 2 - Check Blank Cells",
    "section": "6.4 Finding sparse blank cells",
    "text": "6.4 Finding sparse blank cells\nFor the sake of completeness, we repeat the first part of the last process. Then, we filter for the sheets that are not completely blank (in_or_out != \"Uh oh!\") and we finally filter for all columns that have some NA cells detected. The following step consisted on keeping only the sheets/datasets that had results considering rows missing mandatory information.\n\n\nCode\ndf &lt;- list_sheet_dataset |&gt;\n  purrr::list_flatten() |&gt;\n  purrr::map(\n    ~ tibble::rowid_to_column(., \"id\") |&gt;\n      dplyr::add_row(id = 0) |&gt;\n      dplyr::mutate(\n        row = id + 1,\n        in_or_out = dplyr::if_else(sum(id) == 0, \"Uh oh!\", \"OK\")\n      ) |&gt;\n      dplyr::filter(in_or_out != \"Uh oh!\") |&gt;\n      dplyr::filter_all(dplyr::any_vars(is.na(.))) |&gt;\n      dplyr::filter(id != 0) |&gt;\n      dplyr::select(row)\n  ) |&gt;\n  purrr::keep(~ nrow(.x) &gt;= 1)\n\ndf[1]\n\n\n$Underpasses_Example1\n# A tibble: 14 × 1\n     row\n   &lt;dbl&gt;\n 1     2\n 2     3\n 3     4\n 4     5\n 5     6\n 6     7\n 7     8\n 8     9\n 9    10\n10    11\n11    12\n12    13\n13    14\n14    15",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Step 2 - Check Blank Cells</span>"
    ]
  },
  {
    "objectID": "Quarto/03_SPECIES.html",
    "href": "Quarto/03_SPECIES.html",
    "title": "5  Step 3 - Check Species Validity",
    "section": "",
    "text": "6 Problem description\nIn databases it is frequent to have a species taxa list. Since most of the lists are filled by humans it is expected that the taxa names have typos and different styles of determining unindentified species notation. In that sense it is necessary to check and correct the taxa name using services specifics to that end.\nSince we’re checking crossings obtained by camera traps it is normal that some taxa couldn’t be identified in species level. This represents a more difficult approach as we have to consider the lowest possible taxonomic level. In this context we have to have solutions that tackle the validity of several ways of filling the species field.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Step 3 - Check Species Validity</span>"
    ]
  },
  {
    "objectID": "Quarto/03_SPECIES.html#common-steps",
    "href": "Quarto/03_SPECIES.html#common-steps",
    "title": "5  Step 3 - Check Species Validity",
    "section": "7.1 Common steps",
    "text": "7.1 Common steps\nTo solve this issue, we follow some of the first basic steps from previous checks, as using our customized read_sheet function that provides the full paths of all .xlsx files available in order to read the species sheet from all files.\n\n\nCode\nsource(\"R/FUNCTIONS.R\")\n\n\n\n\nCode\nspreadsheets &lt;- read_sheet(path = \"Example\", results = FALSE)\n\nsp_full &lt;- purrr::map(.x = spreadsheets, function(arquivo) {\n  readxl::read_excel(\n    arquivo,\n    sheet = 6,\n    na = c(\"NA\", \"na\"),\n    col_types = c(\"guess\", \"guess\", \"guess\", \"date\", \"guess\", \"guess\", \"guess\"),\n    col_names = TRUE\n  )\n})\n\n\nWarning: Expecting date in D2996 / R2996C4: got 'xx/07/2019'\n\n\nWarning: Expecting date in D2997 / R2997C4: got 'xx/07/2019'\n\n\nWarning: Expecting date in D2998 / R2998C4: got 'xx/07/2019'\n\n\nWarning: Expecting date in D2999 / R2999C4: got 'xx/07/2019'\n\n\nWarning: Expecting date in D3000 / R3000C4: got 'xx/07/2019'\n\n\nWarning: Expecting date in D3001 / R3001C4: got 'xx/07/2019'\n\n\nWarning: Expecting date in D3002 / R3002C4: got 'xx/07/2019'\n\n\nCode\nhead(sp_full[1][[1]]) # show head of first file\n\n\n# A tibble: 6 × 7\n  Structure_ID   Camera_ID Species       Record_date         Record_time        \n  &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;         &lt;dttm&gt;              &lt;dttm&gt;             \n1 P1 (iguaçu)    cam1      Cavia sp.     2017-05-09 00:00:00 1899-12-31 03:59:00\n2 P3 (varzea)    cam1      Aramides sar… 2017-05-01 00:00:00 1899-12-31 08:37:00\n3 P3 (varzea)    cam1      Leopardus sp. 2017-05-05 00:00:00 1899-12-31 21:09:00\n4 BC2 (drenagem) cam2      Didelphis au… 2018-07-30 00:00:00 1899-12-31 04:18:00\n5 BC2 (drenagem) cam2      Didelphis au… 2018-07-30 00:00:00 1899-12-31 20:02:00\n6 BC2 (drenagem) cam2      Didelphis au… 2018-07-31 00:00:00 1899-12-31 00:10:00\n# ℹ 2 more variables: Record_criteria &lt;lgl&gt;, Behavior &lt;chr&gt;",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Step 3 - Check Species Validity</span>"
    ]
  },
  {
    "objectID": "Quarto/03_SPECIES.html#specific-steps",
    "href": "Quarto/03_SPECIES.html#specific-steps",
    "title": "5  Step 3 - Check Species Validity",
    "section": "7.2 Specific steps",
    "text": "7.2 Specific steps\n\n7.2.1 Full species\nWe first start keeping only valid (full) species. In this sense, we are considering only two-worded terms that doesn’t have sp, spp, ni and similars, which are commonly used to designate unidentified species.\n\n\nCode\nspecies_all_check &lt;- sp_full |&gt;\n  purrr::map(function(x) {\n    x |&gt;\n      dplyr::distinct(Species) |&gt; # unique values for Species\n      dplyr::mutate(Species = stringr::str_squish(Species)) |&gt; # remove whitespaces\n      dplyr::filter(\n        stringr::str_count(Species, \" \") == 1,\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"\\\\.\"),\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"^sp$\"),\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"^sp(?=\\\\.)\"),\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"^spp(?=\\\\.)\"),\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"\\\\(\"),\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"^ni$\"),\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"^NI$\"),\n        !stringr::str_detect(stringr::word(Species, 2, 2), \"^NID$\"),\n        !stringr::str_detect(Species, \"\\\\/\")\n      ) |&gt;\n      dplyr::arrange(Species) |&gt; # alphabetical order\n      dplyr::pull() # vector\n  })\n\nhead(species_all_check[1][[1]]) # show head of first list\n\n\n[1] \"Aramides saracura\" \"Ardea alba\"        \"Cabassous tatouay\"\n[4] \"Caracara plancus\"  \"Cerdocyon thous\"   \"Coendou spinosus\" \n\n\nSince there is a chance that some of the species name have multiple types of spelling considering trailing spaces, we check for names that are similar.\n\n\nCode\nspecies_all_check |&gt;\n  purrr::map(function(x) {\n    table &lt;- table(x)\n\n    table[table &gt; 1]\n  }) |&gt;\n  purrr::keep(~ any(.x &gt; 1))\n\n\nnamed list()\n\n\nHaving the full species list, we use the Global Names Verifier API (https://verifier.globalnames.org/) to check the species names. We opted to do it through Integrated Taxonomic Information System (ITIS) which is data source = 3 on the address for the API. We use the package httr to help on checking the API.\nFor each dataset, we checked all full species names. By the end of the code chunk, we unnested the columns bestResult and scoreDetails that come originally as a data frame from the Global Names Verifier. Following this procedure, we compiled the species results in a single data frame for all species for each dataset.\n\n\nCode\nlist_check_globalnames &lt;- list()\n\nfor (dataset in names(species_all_check)) {\n  species &lt;- species_all_check[[dataset]]\n\n  message(stringr::str_glue(\"Starting dataset {dataset}\"))\n\n  for (sp in species) {\n    sp_ &lt;- stringr::str_replace(sp, \" \", \"_\")\n\n    result &lt;- httr::GET(stringr::str_glue(\n      \"https://verifier.globalnames.org/api/v1/verifications/{sp_}?data_sources=3\"\n    )) # the link for the API check\n\n    list_check_globalnames[[dataset]][[sp_]] &lt;- jsonlite::fromJSON(rawToChar(\n      result$content\n    ))[[\"names\"]] # save the part that interests us on a list composed by the dataset and the species name\n  }\n  # bind the species list on a single data frame unnesting the columns that are a data frame\n  list_check_globalnames[[dataset]][[\"all_results\"]] &lt;- list_check_globalnames[[\n    dataset\n  ]] |&gt;\n    dplyr::bind_rows() |&gt;\n    tidyr::unnest(cols = c(bestResult), names_repair = \"unique\") |&gt;\n    tidyr::unnest(cols = c(scoreDetails), names_repair = \"unique\") |&gt;\n    tibble::as_tibble()\n}\n\nlist_check_globalnames[[1]][[\"all_results\"]]\n\n\n# A tibble: 32 × 40\n   id          name  cardinality matchType...4 dataSourceId dataSourceTitleShort\n   &lt;chr&gt;       &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                &lt;int&gt; &lt;chr&gt;               \n 1 270f98a4-8… Aram…           2 Exact                    3 ITIS                \n 2 771418ff-c… Arde…           2 Exact                    3 ITIS                \n 3 cba54653-8… Caba…           2 Exact                    3 ITIS                \n 4 fe40eafd-8… Cara…           2 Exact                    3 ITIS                \n 5 5b42a2c7-7… Cerd…           2 Exact                    3 ITIS                \n 6 53c82c2e-a… Coen…           2 Exact                    3 ITIS                \n 7 fc6f03f0-f… Colu…           2 Exact                    3 ITIS                \n 8 43452c58-a… Cryp…           2 Exact                    3 ITIS                \n 9 3b28ba6f-d… Cuni…           2 Exact                    3 ITIS                \n10 a0891a66-7… Cyan…           2 Exact                    3 ITIS                \n# ℹ 22 more rows\n# ℹ 34 more variables: curation...7 &lt;chr&gt;, recordId &lt;chr&gt;, outlink &lt;chr&gt;,\n#   entryDate &lt;chr&gt;, sortScore &lt;dbl&gt;, matchedNameID &lt;chr&gt;, matchedName &lt;chr&gt;,\n#   matchedCardinality &lt;int&gt;, matchedCanonicalSimple &lt;chr&gt;,\n#   matchedCanonicalFull &lt;chr&gt;, currentRecordId &lt;chr&gt;, currentNameId &lt;chr&gt;,\n#   currentName &lt;chr&gt;, currentCardinality &lt;int&gt;, currentCanonicalSimple &lt;chr&gt;,\n#   currentCanonicalFull &lt;chr&gt;, taxonomicStatus &lt;chr&gt;, isSynonym &lt;lgl&gt;, …\n\n\nThe next step consisted in creating a full data frame of all the species from all the datasets. We mapped the all_results list from each dataset and then stacked them on a single data frame.\n\n\nCode\nlist_sp &lt;- list_check_globalnames |&gt;\n  purrr::map(\"all_results\") |&gt;\n  dplyr::bind_rows(.id = \"dataset\") |&gt;\n  janitor::clean_names() |&gt;\n  dplyr::mutate(query = stringr::str_replace_all(name, \"_\", \" \"), .after = name)\n\nhead(list_sp)\n\n\n# A tibble: 6 × 42\n  dataset  id                name  query cardinality match_type_4 data_source_id\n  &lt;chr&gt;    &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;\n1 Example1 270f98a4-840c-58… Aram… Aram…           2 Exact                     3\n2 Example1 771418ff-c606-5e… Arde… Arde…           2 Exact                     3\n3 Example1 cba54653-8408-56… Caba… Caba…           2 Exact                     3\n4 Example1 fe40eafd-8adb-5a… Cara… Cara…           2 Exact                     3\n5 Example1 5b42a2c7-767f-58… Cerd… Cerd…           2 Exact                     3\n6 Example1 53c82c2e-a688-59… Coen… Coen…           2 Exact                     3\n# ℹ 35 more variables: data_source_title_short &lt;chr&gt;, curation_7 &lt;chr&gt;,\n#   record_id &lt;chr&gt;, outlink &lt;chr&gt;, entry_date &lt;chr&gt;, sort_score &lt;dbl&gt;,\n#   matched_name_id &lt;chr&gt;, matched_name &lt;chr&gt;, matched_cardinality &lt;int&gt;,\n#   matched_canonical_simple &lt;chr&gt;, matched_canonical_full &lt;chr&gt;,\n#   current_record_id &lt;chr&gt;, current_name_id &lt;chr&gt;, current_name &lt;chr&gt;,\n#   current_cardinality &lt;int&gt;, current_canonical_simple &lt;chr&gt;,\n#   current_canonical_full &lt;chr&gt;, taxonomic_status &lt;chr&gt;, is_synonym &lt;lgl&gt;, …\n\n\nSince we want only the errors, we filtered the column match_type_4 to show every row in which the result was not “Exact”. That means that every species in which the query and the result was not the exact same term were selected to further evaluation.\n\n\nCode\nsp_with_errors &lt;- list_sp |&gt;\n  dplyr::filter(match_type_4 != \"Exact\")\n\nhead(sp_with_errors)\n\n\n# A tibble: 6 × 42\n  dataset  id                name  query cardinality match_type_4 data_source_id\n  &lt;chr&gt;    &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;\n1 Example1 46334ffe-8d29-5e… Guer… Guer…           2 PartialExact              3\n2 Example1 b6551cb7-7323-51… Não_… Não …           0 NoMatch                  NA\n3 Example1 acaac2da-d4a3-51… Subu… Subu…           0 NoMatch                  NA\n4 Example3 c6eeb584-9cf4-5b… Dico… Dico…           2 PartialExact              3\n5 Example3 81a8d8a4-a90b-56… Paux… Paux…           2 PartialExact              3\n6 Example4 15638204-393b-5e… Sylv… Sylv…           2 Fuzzy                     3\n# ℹ 35 more variables: data_source_title_short &lt;chr&gt;, curation_7 &lt;chr&gt;,\n#   record_id &lt;chr&gt;, outlink &lt;chr&gt;, entry_date &lt;chr&gt;, sort_score &lt;dbl&gt;,\n#   matched_name_id &lt;chr&gt;, matched_name &lt;chr&gt;, matched_cardinality &lt;int&gt;,\n#   matched_canonical_simple &lt;chr&gt;, matched_canonical_full &lt;chr&gt;,\n#   current_record_id &lt;chr&gt;, current_name_id &lt;chr&gt;, current_name &lt;chr&gt;,\n#   current_cardinality &lt;int&gt;, current_canonical_simple &lt;chr&gt;,\n#   current_canonical_full &lt;chr&gt;, taxonomic_status &lt;chr&gt;, is_synonym &lt;lgl&gt;, …\n\n\nAfter checking the list of species considered not “Exact”, we found that some species that were not “Exact” must be whitelisted, since we are sure that the name is valid (for example, checking the List of Brazilian Mammals from the Brazilian Mastozoological Society). They can be appended to the names that were considered as “Exact”. This is the last step for the “Full species” inspection.\n\n\nCode\nsp_whitelist &lt;- list_sp |&gt;\n  dplyr::filter(match_type_4 == \"Exact\") |&gt;\n  dplyr::pull(query) |&gt;\n  append(c(\"Guerlinguetus brasiliensis\", \"Guerlinguetus ingrami\")) |&gt; # manually insert species that we know that are correct but the API don't think they are.\n  unique() |&gt;\n  sort()\n\nhead(sp_whitelist)\n\n\n[1] \"Alouatta macconnelli\" \"Ameiva ameiva\"        \"Aramides saracura\"   \n[4] \"Ardea alba\"           \"Bassariscus astutus\"  \"Cabassous tatouay\"   \n\n\n\n\n7.2.2 Imprecise taxa\nFirst of all we have to filter for the species that were not on the query for full species - meaning that all of the terms that were not considered as full species still have to be evaluated.\n\n\nCode\nnon_species_all_check &lt;- purrr::map2(\n  sp_full,\n  species_all_check,\n  function(x, y) {\n    x |&gt;\n      dplyr::distinct(Species) |&gt;\n      dplyr::mutate(Species = stringr::str_squish(Species)) |&gt;\n      dplyr::pull(Species) |&gt;\n      setdiff(y)\n  }\n) |&gt;\n  purrr::compact()\n\nhead(non_species_all_check[[1]])\n\n\n[1] \"Cavia sp.\"      \"Leopardus sp.\"  \"Didelphis sp.\"  \"Dasyprocta sp.\"\n[5] \"Dasypus sp.\"    \"Mammalia\"      \n\n\nWe perform the same approach as we did for the full species, this time for the terms that are not full. By the end, we create a data frame that comprises all terms that were not considered as “Exact” on the query from the API, as well as queries that involved terms as “NI” or “spp”.\n\n\nCode\nlist_non_sp_with_errors &lt;- list()\n\nfor (dataset in names(non_species_all_check)) {\n  species &lt;- non_species_all_check[[dataset]]\n\n  message(stringr::str_glue(\"Starting dataset {dataset}\"))\n\n  for (sp in species) {\n    sp_ &lt;- sp |&gt;\n      stringr::str_remove_all(\"[[:punct:]]\") |&gt;\n      stringr::str_replace_all(pattern = \" \", replacement = \"_\")\n\n    result &lt;- httr::GET(stringr::str_glue(\n      \"https://verifier.globalnames.org/api/v1/verifications/{sp_}?data_sources=3\"\n    )) # the link for the API check\n\n    list_non_sp_with_errors[[dataset]][[sp_]] &lt;- jsonlite::fromJSON(rawToChar(\n      result$content\n    ))[[\"names\"]] # save the part that interests us on a list composed by the dataset and the species name\n  }\n  # bind the species list on a single data frame unnesting the columns that are a data frame\n  list_non_sp_with_errors[[dataset]][[\n    \"all_results\"\n  ]] &lt;- list_non_sp_with_errors[[dataset]] |&gt;\n    dplyr::bind_rows() |&gt;\n    tibble::as_tibble()\n}\n\nnon_sp_with_errors &lt;- list_non_sp_with_errors |&gt;\n  purrr::map(\"all_results\") |&gt;\n  dplyr::bind_rows(.id = \"dataset\") |&gt;\n  janitor::clean_names() |&gt;\n  dplyr::mutate(query = stringr::str_replace_all(name, \"_\", \" \"), .after = name)\n\nhead(non_sp_with_errors)\n\n\n# A tibble: 6 × 10\n  dataset  id          name  query cardinality match_type best_result$dataSour…¹\n  &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                       &lt;int&gt;\n1 Example1 252d16aa-b… Cavi… Cavi…           0 Exact                           3\n2 Example1 12eef028-a… Leop… Leop…           0 Exact                           3\n3 Example1 79ee7bf1-e… Dide… Dide…           0 Exact                           3\n4 Example1 0d57b139-b… Dasy… Dasy…           0 Exact                           3\n5 Example1 1f7764d3-8… Dasy… Dasy…           0 Exact                           3\n6 Example1 9fd2fe86-2… Mamm… Mamm…           1 Exact                           3\n# ℹ abbreviated name: ¹​best_result$dataSourceId\n# ℹ 29 more variables: best_result$dataSourceTitleShort &lt;chr&gt;, $curation &lt;chr&gt;,\n#   $recordId &lt;chr&gt;, $outlink &lt;chr&gt;, $entryDate &lt;chr&gt;, $sortScore &lt;dbl&gt;,\n#   $matchedNameID &lt;chr&gt;, $matchedName &lt;chr&gt;, $matchedCardinality &lt;int&gt;,\n#   $matchedCanonicalSimple &lt;chr&gt;, $matchedCanonicalFull &lt;chr&gt;,\n#   $currentRecordId &lt;chr&gt;, $currentNameId &lt;chr&gt;, $currentName &lt;chr&gt;,\n#   $currentCardinality &lt;int&gt;, $currentCanonicalSimple &lt;chr&gt;, …\n\n\nThe last step is to put together a full list of problems/errors independently if they are for full species or imprecise taxa. In this step we use the sp_whitelist to escape this terms that we think are correct.\n\n\nCode\nsp_with_errors |&gt;\n  dplyr::select(\n    dataset,\n    query,\n    matched_canonical_simple,\n    match_type = match_type_4\n  ) |&gt;\n  dplyr::filter(!query %in% sp_whitelist) |&gt;\n  dplyr::bind_rows(non_sp_with_errors) |&gt;\n  dplyr::arrange(dataset)\n\n\n# A tibble: 57 × 11\n   dataset  query      matched_canonical_si…¹ match_type id    name  cardinality\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n 1 Example1 Não ident… &lt;NA&gt;                   NoMatch    &lt;NA&gt;  &lt;NA&gt;           NA\n 2 Example1 Subulo go… &lt;NA&gt;                   NoMatch    &lt;NA&gt;  &lt;NA&gt;           NA\n 3 Example1 Cavia sp   &lt;NA&gt;                   Exact      252d… Cavi…           0\n 4 Example1 Leopardus… &lt;NA&gt;                   Exact      12ee… Leop…           0\n 5 Example1 Didelphis… &lt;NA&gt;                   Exact      79ee… Dide…           0\n 6 Example1 Dasyproct… &lt;NA&gt;                   Exact      0d57… Dasy…           0\n 7 Example1 Dasypus sp &lt;NA&gt;                   Exact      1f77… Dasy…           0\n 8 Example1 Mammalia   &lt;NA&gt;                   Exact      9fd2… Mamm…           1\n 9 Example1 Aramides … &lt;NA&gt;                   Exact      2c8c… Aram…           0\n10 Example1 Cricetidae &lt;NA&gt;                   Exact      5561… Cric…           1\n# ℹ 47 more rows\n# ℹ abbreviated name: ¹​matched_canonical_simple\n# ℹ 4 more variables: best_result &lt;df[,27]&gt;, data_sources_num &lt;int&gt;,\n#   data_sources_ids &lt;list&gt;, curation &lt;chr&gt;",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Step 3 - Check Species Validity</span>"
    ]
  },
  {
    "objectID": "Quarto/04_STRUCTURE.html",
    "href": "Quarto/04_STRUCTURE.html",
    "title": "6  Step 4 - Check Structures",
    "section": "",
    "text": "7 Problem description\nWe must check if the camera trap Structure_id provided on the sheet Camera_trap is encompassed on the sheets that describe the structures (Underpasses and Overpasses). These sheets also possess the Structure_id field. This column is the link between Camera_trap and Underpasses / Overpasses.\nAll the listed Structure_id provided on the Camera_trap sheet must be present on either Underpasses or Overpasses. The opposite direction is also true, meaning that all the Structure_id provided either on Underpasses or Overpasses must be comprised on Camera_trap.\nWe also have to evaluate if the Structure_id present in the Fencing spreadsheet is included on the Underpasses spreadsheet. We are assuming that there are no fencing for Overpasses.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Step 4 - Check Structures</span>"
    ]
  },
  {
    "objectID": "Quarto/04_STRUCTURE.html#common-steps",
    "href": "Quarto/04_STRUCTURE.html#common-steps",
    "title": "6  Step 4 - Check Structures",
    "section": "8.1 Common steps",
    "text": "8.1 Common steps\nTo solve this issue, we follow some of the first basic steps from previous checks, as using our customized read_sheet function that provides the full paths of all .xlsx files available in order to read the species sheet from all files.\n\n\nCode\nsource(\"R/FUNCTIONS.R\")\n\n\nHere we read the camera trap sheet from all files. We opted to bring the elements of the structures (field Structure_id) to upper case in order to avoid confusions. We also decided do keep only the column Structure_id by using the argument .keep.\n\n\nCode\nct &lt;- read_sheet(\n  path = \"Example\",\n  sheet = \"Camera_trap\",\n  na = c(\"\", \"na\", \"NA\")\n) |&gt;\n  purrr::map(\n    ~ .x |&gt;\n      dplyr::mutate(\n        Structure_id = as.character(stringr::str_to_upper(Structure_id)),\n        .keep = \"none\"\n      )\n  )",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Step 4 - Check Structures</span>"
    ]
  },
  {
    "objectID": "Quarto/04_STRUCTURE.html#specific-steps",
    "href": "Quarto/04_STRUCTURE.html#specific-steps",
    "title": "6  Step 4 - Check Structures",
    "section": "8.2 Specific steps",
    "text": "8.2 Specific steps\n\n8.2.1 Check if there are blank rows on camera trap sheet\nIt is important to check if there are blank rows to avoid the system to find errors where there is no data.\n\n\nCode\nct |&gt;\n  purrr::keep(~ nrow(.x) &gt; 0) |&gt;\n  head(2)\n\n\n$Example1\n# A tibble: 435 × 1\n   Structure_id \n   &lt;chr&gt;        \n 1 BC1 (GALERIA)\n 2 BC1 (GALERIA)\n 3 BC1 (GALERIA)\n 4 BC1 (GALERIA)\n 5 BC1 (GALERIA)\n 6 BC1 (GALERIA)\n 7 BC1 (GALERIA)\n 8 BC1 (GALERIA)\n 9 BC1 (GALERIA)\n10 BC1 (GALERIA)\n# ℹ 425 more rows\n\n$Example2\n# A tibble: 7 × 1\n  Structure_id\n  &lt;chr&gt;       \n1 CE2         \n2 CE3         \n3 CE4         \n4 CE5         \n5 CE6         \n6 CE7         \n7 CE9         \n\n\n\n\n8.2.2 Check duplicated names between underpasses and overpasses\nWe wouldn’t be able to perform a thorough validation if there are duplicated Structure_id between underpasses and overpasses. In that sense, we created two lists called under and over. We kept on the respective lists solely the datasets that comprise either of these types of structures.\nFollowing this step we load all the underpasses spreadsheets from the files.\n\n\nCode\nunder &lt;- read_sheet(\n  path = \"Example\",\n  sheet = \"Underpasses\",\n  na = c(\"\", \"na\", \"NA\")\n) |&gt;\n  purrr::map(\n    ~ .x |&gt;\n      dplyr::mutate(\n        Structure_id = as.character(stringr::str_to_upper(Structure_id)),\n        position = \"under\",\n        .keep = \"none\"\n      )\n  ) |&gt;\n  purrr::keep(~ all(nrow(.x) &gt; 0))\n\nover &lt;- read_sheet(\n  path = \"Example\",\n  sheet = \"Overpasses\",\n  na = c(\"\", \"na\", \"NA\")\n) |&gt;\n  purrr::map(\n    ~ .x |&gt;\n      dplyr::mutate(\n        Structure_id = as.character(stringr::str_to_upper(Structure_id)),\n        position = \"over\",\n        .keep = \"none\"\n      )\n  ) |&gt;\n  purrr::keep(~ nrow(.x) &gt; 0)\n\nhead(under[1])\n\n\n$Example1\n# A tibble: 14 × 2\n   Structure_id     position\n   &lt;chr&gt;            &lt;chr&gt;   \n 1 P1 (IGUAÇU)      under   \n 2 BC1 (GALERIA)    under   \n 3 P2 (MAURICIO)    under   \n 4 BC2 (DRENAGEM)   under   \n 5 BCS1             under   \n 6 P3 (VARZEA)      under   \n 7 P4 (FAZENDA)     under   \n 8 P5 (SAPEZAL)     under   \n 9 P6 (PASSA TRÊS)  under   \n10 P7 (LOURENÇO)    under   \n11 P8 (DAS PEDRAS)  under   \n12 BCS2             under   \n13 P9 (CACHORROS)   under   \n14 P10 (AMOLA FACA) under   \n\n\nCode\nhead(over[1])\n\n\n$Example1\n# A tibble: 1 × 2\n  Structure_id position\n  &lt;chr&gt;        &lt;chr&gt;   \n1 PAEREA       over    \n\n\nThe next step is to merge underpasses and overpasses Structure_id from each dataset into a single dataframe.\n\n\nCode\n# Binding under and over in one only list\nunder_over &lt;- list()\n\nfor (i in names(ct)) {\n  exists_in_under &lt;- i %in% names(under)\n  exists_in_over &lt;- i %in% names(over)\n\n  if (exists_in_under & exists_in_over) {\n    under_over[[i]] &lt;- dplyr::bind_rows(under[[i]], over[[i]])\n  } else if (exists_in_under & exists_in_over == FALSE) {\n    under_over[[i]] &lt;- under[[i]]\n  } else {\n    under_over[[i]] &lt;- over[[i]]\n  }\n}\n\nhead(under_over[1])\n\n\n$Example1\n# A tibble: 15 × 2\n   Structure_id     position\n   &lt;chr&gt;            &lt;chr&gt;   \n 1 P1 (IGUAÇU)      under   \n 2 BC1 (GALERIA)    under   \n 3 P2 (MAURICIO)    under   \n 4 BC2 (DRENAGEM)   under   \n 5 BCS1             under   \n 6 P3 (VARZEA)      under   \n 7 P4 (FAZENDA)     under   \n 8 P5 (SAPEZAL)     under   \n 9 P6 (PASSA TRÊS)  under   \n10 P7 (LOURENÇO)    under   \n11 P8 (DAS PEDRAS)  under   \n12 BCS2             under   \n13 P9 (CACHORROS)   under   \n14 P10 (AMOLA FACA) under   \n15 PAEREA           over    \n\n\nNow we can check if there are duplicated names for Structure_id. This checks if there are duplicates on overpasses, underpasses and the merge of underpasses and overpasses.\n\n\nCode\nunder_over |&gt;\n  dplyr::bind_rows(.id = \"Dataset\") |&gt;\n  dplyr::count(Dataset, Structure_id, sort = TRUE) |&gt;\n  dplyr::filter(n &gt; 1)\n\n\n# A tibble: 2 × 3\n  Dataset  Structure_id     n\n  &lt;chr&gt;    &lt;chr&gt;        &lt;int&gt;\n1 Example3 OAC24            2\n2 Example3 OAC89            2\n\n\n\n\n8.2.3 Check if the structures in Camera Trap sheet are in either Underpasses and Overpasses sheet and vice-versa\n\n8.2.3.1 Camera trap x Crossing structures\nInitially, we got from every dataset, the Structure_id from their camera trap spreadsheet and the same field from their underpasses and overpasses spreadsheet. We compared the strings from camera traps and underpasses and overpasses. We expect that for every string on Structure_id camera trap sheet to be included on either underpasses or overpasses sheet.\n\n\nCode\nct_diff_under_over &lt;- purrr::map(names(ct), function(x) {\n  a &lt;- ct[[x]]\n  uo &lt;- under_over[[x]]\n\n  base::setdiff(a$Structure_id, uo$Structure_id) |&gt;\n    tibble::enframe(name = \"Erro\", value = \"Structure_id\") |&gt;\n    dplyr::mutate(status = \"no_under_nor_over\", position = \"in_ct\")\n}) |&gt;\n  purrr::set_names(names(ct)) |&gt;\n  purrr::keep(~ nrow(.x) &gt; 0) |&gt; # discard datasets without errors\n  dplyr::bind_rows(.id = \"Dataset\")\n\nct_diff_under_over |&gt;\n  print(n = Inf)\n\n\n# A tibble: 60 × 5\n   Dataset   Erro Structure_id             status            position\n   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;                    &lt;chr&gt;             &lt;chr&gt;   \n 1 Example3     1 KM 437                   no_under_nor_over in_ct   \n 2 Example3     2 AR08                     no_under_nor_over in_ct   \n 3 Example3     3 AR10                     no_under_nor_over in_ct   \n 4 Example3     4 KM 158                   no_under_nor_over in_ct   \n 5 Example3     5 KM 192                   no_under_nor_over in_ct   \n 6 Example3     6 KM 248                   no_under_nor_over in_ct   \n 7 Example3     7 KM 636,7                 no_under_nor_over in_ct   \n 8 Example3     8 KM 701                   no_under_nor_over in_ct   \n 9 Example3     9 KM 770                   no_under_nor_over in_ct   \n10 Example3    10 KM 98,3                  no_under_nor_over in_ct   \n11 Example3    11 ANTES DO CANTEIRO        no_under_nor_over in_ct   \n12 Example3    12 AR100                    no_under_nor_over in_ct   \n13 Example3    13 AR14F                    no_under_nor_over in_ct   \n14 Example3    14 AR15/IGAPÓ               no_under_nor_over in_ct   \n15 Example3    15 AR27                     no_under_nor_over in_ct   \n16 Example3    16 AR58                     no_under_nor_over in_ct   \n17 Example3    17 AR59                     no_under_nor_over in_ct   \n18 Example3    18 AR60                     no_under_nor_over in_ct   \n19 Example3    19 AR61                     no_under_nor_over in_ct   \n20 Example3    20 AR89                     no_under_nor_over in_ct   \n21 Example3    21 AR94F                    no_under_nor_over in_ct   \n22 Example3    22 ÁREA VERDE DIREITA       no_under_nor_over in_ct   \n23 Example3    23 ÁREA VERDE/ ESQUERDA     no_under_nor_over in_ct   \n24 Example3    24 ÁREA VERDE/OAC36 (PERTO) no_under_nor_over in_ct   \n25 Example3    25 CAIPIRÃO                 no_under_nor_over in_ct   \n26 Example3    26 ENTRE OAC139 OAE PILÃO   no_under_nor_over in_ct   \n27 Example3    27 FRAGMENTO                no_under_nor_over in_ct   \n28 Example3    28 FRAGMENTO KM 153         no_under_nor_over in_ct   \n29 Example3    29 FRAGMENTO KM 91          no_under_nor_over in_ct   \n30 Example3    30 FRAGMENTO KM266          no_under_nor_over in_ct   \n31 Example3    31 FRAGMENTO LADO PRAD LD   no_under_nor_over in_ct   \n32 Example3    32 KM104                    no_under_nor_over in_ct   \n33 Example3    33 KM128                    no_under_nor_over in_ct   \n34 Example3    34 KM152                    no_under_nor_over in_ct   \n35 Example3    35 KM191                    no_under_nor_over in_ct   \n36 Example3    36 KM214                    no_under_nor_over in_ct   \n37 Example3    37 KM223,3                  no_under_nor_over in_ct   \n38 Example3    38 KM224                    no_under_nor_over in_ct   \n39 Example3    39 KM296,7                  no_under_nor_over in_ct   \n40 Example3    40 KM317                    no_under_nor_over in_ct   \n41 Example3    41 KM349                    no_under_nor_over in_ct   \n42 Example3    42 KM455                    no_under_nor_over in_ct   \n43 Example3    43 KM501                    no_under_nor_over in_ct   \n44 Example3    44 KM575                    no_under_nor_over in_ct   \n45 Example3    45 KM681,4                  no_under_nor_over in_ct   \n46 Example3    46 KM711                    no_under_nor_over in_ct   \n47 Example3    47 KM797                    no_under_nor_over in_ct   \n48 Example3    48 OAC NOVO (CAM006)        no_under_nor_over in_ct   \n49 Example3    49 OAC110/KM91              no_under_nor_over in_ct   \n50 Example3    50 OAC14                    no_under_nor_over in_ct   \n51 Example3    51 OAC18                    no_under_nor_over in_ct   \n52 Example3    52 OAC251                   no_under_nor_over in_ct   \n53 Example3    53 OAC74/AR40               no_under_nor_over in_ct   \n54 Example3    54 PONTE PIAUÍ KM379        no_under_nor_over in_ct   \n55 Example3    55 PRÓX. PONTE DOS MILAGRES no_under_nor_over in_ct   \n56 Example3    56 PRÓXIMO À OAC            no_under_nor_over in_ct   \n57 Example3    57 PROXIMO A OAC 36A        no_under_nor_over in_ct   \n58 Example3    58 RASTRO/DIREITA           no_under_nor_over in_ct   \n59 Example3    59 OAC089                   no_under_nor_over in_ct   \n60 Example3    60 OAC63                    no_under_nor_over in_ct   \n\n\n\n\n8.2.3.2 Crossing structures x Camera trap\nWe apply here the same strategy as above, but in the opposite direction.\n\n\nCode\nunder_over_diff_ct &lt;- purrr::map(names(ct), function(x) {\n  a &lt;- ct[[x]]\n  uo &lt;- under_over[[x]]\n\n  base::setdiff(uo$Structure_id, a$Structure_id) |&gt;\n    tibble::enframe(name = \"Erro\", value = \"Structure_id\") |&gt;\n    dplyr::mutate(status = \"not_in_ct\") |&gt;\n    dplyr::left_join(under_over[[x]], by = \"Structure_id\")\n}) |&gt;\n  purrr::set_names(names(ct)) |&gt;\n  purrr::keep(~ nrow(.x) &gt; 0) |&gt;\n  dplyr::bind_rows(.id = \"Dataset\")\n\ndplyr::bind_rows(ct_diff_under_over, under_over_diff_ct) |&gt;\n  dplyr::arrange(Dataset) |&gt;\n  print(n = Inf)\n\n\n# A tibble: 67 × 5\n   Dataset   Erro Structure_id               status            position\n   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;                      &lt;chr&gt;             &lt;chr&gt;   \n 1 Example1     1 BCS1                       not_in_ct         under   \n 2 Example1     2 BCS2                       not_in_ct         under   \n 3 Example1     3 PAEREA                     not_in_ct         over    \n 4 Example3     1 KM 437                     no_under_nor_over in_ct   \n 5 Example3     2 AR08                       no_under_nor_over in_ct   \n 6 Example3     3 AR10                       no_under_nor_over in_ct   \n 7 Example3     4 KM 158                     no_under_nor_over in_ct   \n 8 Example3     5 KM 192                     no_under_nor_over in_ct   \n 9 Example3     6 KM 248                     no_under_nor_over in_ct   \n10 Example3     7 KM 636,7                   no_under_nor_over in_ct   \n11 Example3     8 KM 701                     no_under_nor_over in_ct   \n12 Example3     9 KM 770                     no_under_nor_over in_ct   \n13 Example3    10 KM 98,3                    no_under_nor_over in_ct   \n14 Example3    11 ANTES DO CANTEIRO          no_under_nor_over in_ct   \n15 Example3    12 AR100                      no_under_nor_over in_ct   \n16 Example3    13 AR14F                      no_under_nor_over in_ct   \n17 Example3    14 AR15/IGAPÓ                 no_under_nor_over in_ct   \n18 Example3    15 AR27                       no_under_nor_over in_ct   \n19 Example3    16 AR58                       no_under_nor_over in_ct   \n20 Example3    17 AR59                       no_under_nor_over in_ct   \n21 Example3    18 AR60                       no_under_nor_over in_ct   \n22 Example3    19 AR61                       no_under_nor_over in_ct   \n23 Example3    20 AR89                       no_under_nor_over in_ct   \n24 Example3    21 AR94F                      no_under_nor_over in_ct   \n25 Example3    22 ÁREA VERDE DIREITA         no_under_nor_over in_ct   \n26 Example3    23 ÁREA VERDE/ ESQUERDA       no_under_nor_over in_ct   \n27 Example3    24 ÁREA VERDE/OAC36 (PERTO)   no_under_nor_over in_ct   \n28 Example3    25 CAIPIRÃO                   no_under_nor_over in_ct   \n29 Example3    26 ENTRE OAC139 OAE PILÃO     no_under_nor_over in_ct   \n30 Example3    27 FRAGMENTO                  no_under_nor_over in_ct   \n31 Example3    28 FRAGMENTO KM 153           no_under_nor_over in_ct   \n32 Example3    29 FRAGMENTO KM 91            no_under_nor_over in_ct   \n33 Example3    30 FRAGMENTO KM266            no_under_nor_over in_ct   \n34 Example3    31 FRAGMENTO LADO PRAD LD     no_under_nor_over in_ct   \n35 Example3    32 KM104                      no_under_nor_over in_ct   \n36 Example3    33 KM128                      no_under_nor_over in_ct   \n37 Example3    34 KM152                      no_under_nor_over in_ct   \n38 Example3    35 KM191                      no_under_nor_over in_ct   \n39 Example3    36 KM214                      no_under_nor_over in_ct   \n40 Example3    37 KM223,3                    no_under_nor_over in_ct   \n41 Example3    38 KM224                      no_under_nor_over in_ct   \n42 Example3    39 KM296,7                    no_under_nor_over in_ct   \n43 Example3    40 KM317                      no_under_nor_over in_ct   \n44 Example3    41 KM349                      no_under_nor_over in_ct   \n45 Example3    42 KM455                      no_under_nor_over in_ct   \n46 Example3    43 KM501                      no_under_nor_over in_ct   \n47 Example3    44 KM575                      no_under_nor_over in_ct   \n48 Example3    45 KM681,4                    no_under_nor_over in_ct   \n49 Example3    46 KM711                      no_under_nor_over in_ct   \n50 Example3    47 KM797                      no_under_nor_over in_ct   \n51 Example3    48 OAC NOVO (CAM006)          no_under_nor_over in_ct   \n52 Example3    49 OAC110/KM91                no_under_nor_over in_ct   \n53 Example3    50 OAC14                      no_under_nor_over in_ct   \n54 Example3    51 OAC18                      no_under_nor_over in_ct   \n55 Example3    52 OAC251                     no_under_nor_over in_ct   \n56 Example3    53 OAC74/AR40                 no_under_nor_over in_ct   \n57 Example3    54 PONTE PIAUÍ KM379          no_under_nor_over in_ct   \n58 Example3    55 PRÓX. PONTE DOS MILAGRES   no_under_nor_over in_ct   \n59 Example3    56 PRÓXIMO À OAC              no_under_nor_over in_ct   \n60 Example3    57 PROXIMO A OAC 36A          no_under_nor_over in_ct   \n61 Example3    58 RASTRO/DIREITA             no_under_nor_over in_ct   \n62 Example3    59 OAC089                     no_under_nor_over in_ct   \n63 Example3    60 OAC63                      no_under_nor_over in_ct   \n64 Example3     1 OAC36A                     not_in_ct         under   \n65 Example3     2 OACNOVO                    not_in_ct         under   \n66 Example3     3 PRÓXIMO À OAC/ ESTACA 6555 not_in_ct         under   \n67 Example3     4 OAC074                     not_in_ct         under   \n\n\n\n\n\n8.2.4 Check if fences are present on underpasses\nFirstly we read the Fencing spreadsheet for every dataset, filtering for only those who have any row filled.\n\n\nCode\nfences &lt;- read_sheet(path = \"Example\", sheet = \"Fencing\", na = \"NA\") |&gt;\n  purrr::map(\n    ~ .x |&gt;\n      dplyr::mutate(\n        Structure_id = as.character(stringr::str_to_upper(Structure_id)),\n        position = \"under\",\n        .keep = \"none\"\n      )\n  ) |&gt;\n  purrr::keep(~ nrow(.x) &gt; 0)\n\n\nWe then check if all the Structure_id listed on the Fencing spreadsheet are comprised on the Structure_id on the Underpasses spreadsheet.\n\n\nCode\nfences_diff_under &lt;- purrr::map(names(fences), function(x) {\n  a &lt;- fences[[x]]\n  u &lt;- under[[x]]\n\n  base::setdiff(a$Structure_id, u$Structure_id) |&gt;\n    tibble::enframe(name = \"Erro\", value = \"Structure_id\") |&gt;\n    dplyr::mutate(status = \"no_under\", position = \"in_fences\")\n}) |&gt;\n  purrr::set_names(names(fences)) |&gt;\n  purrr::keep(~ nrow(.x) &gt; 0) |&gt;\n  dplyr::bind_rows(.id = \"Dataset\")\n\nfences_diff_under |&gt;\n  print(n = Inf)\n\n\n# A tibble: 0 × 0\n\n\nWe then proceed on the opposite direction, checking if there are Structure_id on the Underpasses spreadsheet not encompassed on Fencing. Obviously, there are passages that could not have been fenced, however, we play it conservatively to check with the authors if this is the case or if they have forgotten to fill the Fencing spreadsheet correctly.\n\n\nCode\nunder_fences_diff &lt;- purrr::map(names(fences), function(x) {\n  a &lt;- fences[[x]]\n  u &lt;- under[[x]]\n\n  base::setdiff(u$Structure_id, a$Structure_id) |&gt;\n    tibble::enframe(name = \"Erro\", value = \"Structure_id\") |&gt;\n    dplyr::mutate(status = \"no_fences\", position = \"in_under\")\n}) |&gt;\n  purrr::set_names(names(fences)) |&gt;\n  purrr::keep(~ nrow(.x) &gt; 0) |&gt;\n  dplyr::bind_rows(.id = \"Dataset\")\n\nunder_fences_diff |&gt;\n  print(n = Inf)\n\n\n# A tibble: 0 × 0",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Step 4 - Check Structures</span>"
    ]
  },
  {
    "objectID": "Quarto/05_ID_CAMERA.html",
    "href": "Quarto/05_ID_CAMERA.html",
    "title": "7  Step 5 - Check ID on Camera",
    "section": "",
    "text": "8 Problem Description\nThis document explains the process of verifying camera IDs between two datasets: the camera trap setup data and the species records data. The goal is to identify any mismatches or inconsistencies in camera IDs between these datasets.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Step 5 - Check ID on Camera</span>"
    ]
  },
  {
    "objectID": "Quarto/05_ID_CAMERA.html#common-steps",
    "href": "Quarto/05_ID_CAMERA.html#common-steps",
    "title": "7  Step 5 - Check ID on Camera",
    "section": "9.1 Common steps",
    "text": "9.1 Common steps\nTo solve this issue, we follow some of the first basic steps from previous checks, as using our customized read_sheet function that provides the full paths of all .xlsx files available in order to read the species sheet from all files.\n\n\nCode\nsource(\"R/FUNCTIONS.R\")",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Step 5 - Check ID on Camera</span>"
    ]
  },
  {
    "objectID": "Quarto/05_ID_CAMERA.html#data-loading",
    "href": "Quarto/05_ID_CAMERA.html#data-loading",
    "title": "7  Step 5 - Check ID on Camera",
    "section": "9.2 Data Loading",
    "text": "9.2 Data Loading\nWe load two datasets from the spreadsheet: 1. Camera trap setup data (ct) 2. Species records data (rec)\n\n\nCode\n# Read camera trap setup data\nct &lt;- read_sheet(sheet = \"Camera_trap\")\n\n# Read species records data\nrec &lt;- read_sheet(sheet = \"Species_records_camera\")",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Step 5 - Check ID on Camera</span>"
    ]
  },
  {
    "objectID": "Quarto/05_ID_CAMERA.html#verification-process",
    "href": "Quarto/05_ID_CAMERA.html#verification-process",
    "title": "7  Step 5 - Check ID on Camera",
    "section": "9.3 Verification Process",
    "text": "9.3 Verification Process\nThe verification process consists of two main checks:\n\n9.3.1 Records to Camera Trap Check\nThis check identifies any camera IDs in the species records that don’t exist in the camera trap data:\n\n\nCode\nrecord_to_ct &lt;- purrr::map2(ct, rec, function(c, r) {\n  base::setdiff(r$Camera_id, c$Camera_id) |&gt;\n    tibble::enframe(name = \"Error\", value = \"Camera_id\") |&gt;\n    dplyr::mutate(note = \"Record without camera on sheet\")\n}) |&gt;\n  purrr::discard(~ nrow(.x) == 0) |&gt;\n  dplyr::bind_rows(.id = \"Dataset\")\n\nhead(record_to_ct)\n\n\n# A tibble: 0 × 0\n\n\n\n\n9.3.2 Camera Trap to Records Check\nThis check identifies any camera IDs in the camera trap data that don’t have corresponding records:\n\n\nCode\nct_to_record &lt;- purrr::map2(ct, rec, function(c, r) {\n  base::setdiff(c$Camera_id, r$Camera_id) |&gt;\n    tibble::enframe(name = \"Error\", value = \"Camera_id\") |&gt;\n    dplyr::mutate(note = \"Camera without record on sheet\")\n}) |&gt;\n  purrr::discard(~ nrow(.x) == 0) |&gt;\n  dplyr::bind_rows(.id = \"Dataset\")\n\nhead(ct_to_record)\n\n\n# A tibble: 6 × 4\n  Dataset  Error Camera_id note                          \n  &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;                         \n1 Example1     1 -         Camera without record on sheet\n2 Example3     1 CAM000    Camera without record on sheet\n3 Example4     1 MX007     Camera without record on sheet\n4 Example6     1 cam1_C    Camera without record on sheet\n5 Example6     2 cam2_C    Camera without record on sheet\n6 Example6     3 cam5_C    Camera without record on sheet",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Step 5 - Check ID on Camera</span>"
    ]
  },
  {
    "objectID": "Quarto/05_ID_CAMERA.html#output-generation",
    "href": "Quarto/05_ID_CAMERA.html#output-generation",
    "title": "7  Step 5 - Check ID on Camera",
    "section": "9.4 Output Generation",
    "text": "9.4 Output Generation\nFinally, we combine both checks and save the results to an Excel file:\n\n\nCode\nrecord_to_ct |&gt;\n  dplyr::bind_rows(ct_to_record) |&gt;\n  openxlsx::write.xlsx(\"Output/check_id_errors.xlsx\", asTable = TRUE)",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Step 5 - Check ID on Camera</span>"
    ]
  },
  {
    "objectID": "Quarto/05_ID_CAMERA.html#results-interpretation",
    "href": "Quarto/05_ID_CAMERA.html#results-interpretation",
    "title": "7  Step 5 - Check ID on Camera",
    "section": "9.5 Results Interpretation",
    "text": "9.5 Results Interpretation\nThe output file check_id_errors.xlsx contains two types of errors:\n\nCamera IDs that appear in species records but not in the camera trap data\nCamera IDs that appear in the camera trap data but have no corresponding species records\n\nThis helps identify potential data entry errors or missing information in either dataset.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Step 5 - Check ID on Camera</span>"
    ]
  },
  {
    "objectID": "Quarto/06_DATE.html",
    "href": "Quarto/06_DATE.html",
    "title": "8  Step 6 - Check Date Consistency",
    "section": "",
    "text": "9 Problem Description\nThis document describes the process of checking date and time consistency in the camera trap dataset. The goal is to identify records with inconsistent sampling periods, future dates, or species records outside the sampling interval.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Step 6 - Check Date Consistency</span>"
    ]
  },
  {
    "objectID": "Quarto/06_DATE.html#common-steps",
    "href": "Quarto/06_DATE.html#common-steps",
    "title": "8  Step 6 - Check Date Consistency",
    "section": "10.1 Common Steps",
    "text": "10.1 Common Steps\nWe start by loading the required functions and packages.\n\n\nCode\nlibrary(hms)\nlibrary(tidyverse)\nsource(\"R/FUNCTIONS.R\")\n\n\nWe load the camera trap setup data for further checks.\n\n\nCode\nct &lt;- read_sheet(sheet = \"Camera_trap\", na = c(\"NA\", \"na\"))",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Step 6 - Check Date Consistency</span>"
    ]
  },
  {
    "objectID": "Quarto/06_DATE.html#check-for-short-sampling-durations",
    "href": "Quarto/06_DATE.html#check-for-short-sampling-durations",
    "title": "8  Step 6 - Check Date Consistency",
    "section": "10.2 Check for Short Sampling Durations",
    "text": "10.2 Check for Short Sampling Durations\nWe identify camera deployments with a sampling duration of less than 24 hours (86,400 seconds).\n\n\nCode\ncheck_date_before &lt;- map(.x = ct, function(dataset) {\n    dataset |&gt;\n        dttm_update(date_col = \"Start_date\", time_col = \"Start_time\") |&gt;\n        dttm_update(date_col = \"End_date\", time_col = \"End_time\") |&gt;\n        select(-ends_with(\"_time\")) |&gt;\n        mutate(\n            duration = as.duration(Start_date %--% End_date)\n        ) |&gt;\n        filter(duration &lt; 86400)\n}) |&gt;\n    bind_rows(.id = \"dataset\") |&gt;\n    select(dataset, Camera_id, Start_date:duration)\n\ncheck_date_before\n\n\n# A tibble: 0 × 30\n# ℹ 30 variables: dataset &lt;chr&gt;, Camera_id &lt;chr&gt;, Start_date &lt;dttm&gt;,\n#   End_date &lt;dttm&gt;, Camera_problem &lt;chr&gt;, Problem1_from &lt;dttm&gt;,\n#   Problem1_to &lt;dttm&gt;, Problem2_from &lt;dttm&gt;, Problem2_to &lt;dttm&gt;,\n#   Problem3_from &lt;dttm&gt;, Problem3_to &lt;dttm&gt;, Problem4_from &lt;dttm&gt;,\n#   Problem4_to &lt;dttm&gt;, Problem5_from &lt;dttm&gt;, Problem5_to &lt;dttm&gt;,\n#   Problem6_from &lt;dttm&gt;, Problem6_to &lt;dttm&gt;, Problem7_from &lt;dttm&gt;,\n#   Problem7_to &lt;dttm&gt;, Problem8_from &lt;dttm&gt;, Problem8_to &lt;dttm&gt;, …",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Step 6 - Check Date Consistency</span>"
    ]
  },
  {
    "objectID": "Quarto/06_DATE.html#check-for-excessively-long-sampling-durations",
    "href": "Quarto/06_DATE.html#check-for-excessively-long-sampling-durations",
    "title": "8  Step 6 - Check Date Consistency",
    "section": "10.3 Check for Excessively Long Sampling Durations",
    "text": "10.3 Check for Excessively Long Sampling Durations\nWe identify deployments with a sampling duration longer than 3 months (7,776,000 seconds).\n\n\nCode\ncheck_date_after &lt;- map(.x = ct, function(dataset) {\n    dataset |&gt;\n        dttm_update(date_col = \"Start_date\", time_col = \"Start_time\") |&gt;\n        dttm_update(date_col = \"End_date\", time_col = \"End_time\") |&gt;\n        select(-ends_with(\"_time\")) |&gt;\n        mutate(\n            duration = as.duration(Start_date %--% End_date)\n        ) |&gt;\n        filter(duration &gt; 7776000)\n}) |&gt;\n    bind_rows(.id = \"dataset\") |&gt;\n    select(dataset, Camera_id, Start_date:duration)\n\ncheck_date_after\n\n\n# A tibble: 16 × 30\n   dataset  Camera_id  Start_date          End_date            Camera_problem\n   &lt;chr&gt;    &lt;chr&gt;      &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;         \n 1 Example4 MX2_004    2018-09-08 14:50:00 2019-09-29 12:21:00 No            \n 2 Example4 MX2_003    2018-09-08 15:29:00 2019-09-08 13:13:00 No            \n 3 Example4 MX2_010    2018-09-09 15:19:00 2019-03-04 11:24:00 Sí            \n 4 Example4 MX007      2018-09-08 17:58:00 2019-03-05 11:54:00 Sí            \n 5 Example4 MX2_009    2018-09-09 14:36:00 2019-03-05 12:16:00 Sí            \n 6 Example4 MX2_001    2018-09-09 12:31:00 2019-07-28 11:38:00 Sí            \n 7 Example4 MX2_006    2018-09-08 11:51:00 2019-03-05 13:22:00 Sí            \n 8 Example4 MX2_013    2018-08-15 13:55:00 2019-01-27 13:52:00 Sí            \n 9 Example4 MX2_014    2018-08-15 14:20:00 2019-03-14 14:24:00 Sí            \n10 Example4 MX2_015    2018-08-15 15:15:00 2019-05-24 13:38:00 No            \n11 Example4 MX2_016    2018-08-15 16:35:00 2019-08-09 16:44:00 No            \n12 Example4 MX2_019    2018-08-16 10:25:00 2018-12-27 12:27:00 Sí            \n13 Example4 MX2_018    2018-08-16 09:30:00 2018-12-30 16:55:00 Sí            \n14 Example4 MX2_017    2018-08-15 17:32:00 2019-09-29 13:16:00 No            \n15 Example5 camGRI_WPB 2017-02-14 19:00:00 2020-02-14 23:59:00 No            \n16 Example5 camGRI_RB  2017-02-14 19:00:00 2020-02-14 23:59:00 No            \n# ℹ 25 more variables: Problem1_from &lt;dttm&gt;, Problem1_to &lt;dttm&gt;,\n#   Problem2_from &lt;dttm&gt;, Problem2_to &lt;dttm&gt;, Problem3_from &lt;dttm&gt;,\n#   Problem3_to &lt;dttm&gt;, Problem4_from &lt;dttm&gt;, Problem4_to &lt;dttm&gt;,\n#   Problem5_from &lt;dttm&gt;, Problem5_to &lt;dttm&gt;, Problem6_from &lt;dttm&gt;,\n#   Problem6_to &lt;dttm&gt;, Problem7_from &lt;dttm&gt;, Problem7_to &lt;dttm&gt;,\n#   Problem8_from &lt;dttm&gt;, Problem8_to &lt;dttm&gt;, Problem9_from &lt;dttm&gt;,\n#   Problem9_to &lt;dttm&gt;, Problem10_from &lt;dttm&gt;, Problem10_to &lt;dttm&gt;, …",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Step 6 - Check Date Consistency</span>"
    ]
  },
  {
    "objectID": "Quarto/06_DATE.html#check-for-future-dates",
    "href": "Quarto/06_DATE.html#check-for-future-dates",
    "title": "8  Step 6 - Check Date Consistency",
    "section": "10.4 Check for Future Dates",
    "text": "10.4 Check for Future Dates\nWe flag deployments with start or end dates set in the future. We defined the threshold date as April 30th, 2025.\n\n\nCode\ncheck_date_future &lt;- map(.x = ct, function(dataset) {\n    data_thresh &lt;- \"2025-04-30\"\n    dataset |&gt;\n        mutate(\n            date_start = ymd(as.character(Start_date)),\n            date_end = ymd(as.character(End_date))\n        ) |&gt;\n        filter(if_any(starts_with(\"date_\"), ~ .x &gt; data_thresh))\n}) |&gt;\n    bind_rows(.id = \"dataset\") |&gt;\n    select(dataset, Camera_id, date_start:date_end)\n\ncheck_date_future\n\n\n# A tibble: 0 × 4\n# ℹ 4 variables: dataset &lt;chr&gt;, Camera_id &lt;chr&gt;, date_start &lt;date&gt;,\n#   date_end &lt;date&gt;",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Step 6 - Check Date Consistency</span>"
    ]
  },
  {
    "objectID": "Quarto/06_DATE.html#check-species-records-within-sampling-interval",
    "href": "Quarto/06_DATE.html#check-species-records-within-sampling-interval",
    "title": "8  Step 6 - Check Date Consistency",
    "section": "10.5 Check Species Records Within Sampling Interval",
    "text": "10.5 Check Species Records Within Sampling Interval\nWe load the species records data for cross-checking with camera trap intervals.\n\n\nCode\nrec &lt;- read_sheet(\n  sheet = \"Species_records_camera\", \n  na = c(\"NA\", \"na\")\n  )\n\ndatasets &lt;- names(rec)\n\n\nWe check if each species record falls within the sampling interval of the corresponding camera.\n\n\nCode\nspecies_records_within_ct_date &lt;- list()\nerror_log &lt;- tibble(dataset = character(), error_message = character())\n\nfor (dataset in datasets) {\n    message(str_glue(\"Starting dataset {dataset}\\n\"))\n    tryCatch(\n        {\n            camera &lt;- ct[[dataset]] |&gt;\n                select(Structure_id, Camera_id, Start_date, End_date)\n\n            species_records_within_ct_date[[dataset]] &lt;- rec[[dataset]] |&gt;\n                inner_join(camera, by = c(\"Camera_id\", \"Structure_id\")) |&gt;\n                mutate(\n                    across(ends_with(\"date\"), as_datetime),\n                    row = row_number(),\n                    check = case_when(\n                        Record_date %within% c(Start_date %--% End_date) ~\n                            \"YES\",\n                        TRUE ~ \"NO\"\n                    )\n                ) |&gt;\n                filter(check == \"NO\") |&gt;\n                select(row, Species, Camera_id, ends_with(\"date\"), check)\n            message(str_glue(\"Finalizing dataset {dataset}\\n\"))\n        },\n        error = function(e) {\n            msg &lt;- as.character(e$message)\n            error_log &lt;&lt;- bind_rows(\n                error_log,\n                tibble(dataset = dataset, error_message = msg)\n            )\n            message(str_glue(\"Error in dataset {dataset}: {msg}\\n\"))\n            return(NULL)\n        }\n    )\n}\n\nerror_log\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: dataset &lt;chr&gt;, error_message &lt;chr&gt;\n\n\nWe summarize and print the number of records outside the sampling interval for each dataset.\n\n\nCode\nspecies_records_within_ct_date |&gt;\n    discard(~ nrow(.x) == 0) |&gt;\n    bind_rows(.id = \"dataset\") |&gt;\n    count(dataset, sort = TRUE) |&gt;\n    print(n = Inf)\n\n\n# A tibble: 4 × 2\n  dataset      n\n  &lt;chr&gt;    &lt;int&gt;\n1 Example1   304\n2 Example4   104\n3 Example2     1\n4 Example3     1\n\n\nWe export the records outside the sampling interval to an Excel file.\n\n\nCode\nspecies_records_within_ct_date |&gt; \n  openxlsx::write.xlsx( \"Output/REGISTROS_SP_FORA_DA_DATA.xlsx\", asTable = TRUE, colWidths = \"auto\" )",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Step 6 - Check Date Consistency</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html",
    "href": "Quarto/07_DUPLICATED_CT.html",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "",
    "text": "10 Problem Description\nThis document describes the process of identifying duplicated camera IDs within the same structure in the camera trap setup data. The goal is to ensure that each camera within a structure is uniquely identified, avoiding overlaps that could compromise data integrity.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#common-steps",
    "href": "Quarto/07_DUPLICATED_CT.html#common-steps",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.1 Common steps",
    "text": "11.1 Common steps\nWe use our customized read_sheet function to load the camera trap setup data from all available spreadsheets. Hence, we need to load the FUNCTIONS.R. Another function, also needed to create unique id’s called unique_id is loaded. Also, two special operators from the lubridate package are brought to the memory.\n\n\nCode\nsource(\"R/FUNCTIONS.R\")\n\nuse(\"lubridate\", c(\"%within%\", \"%--%\"))",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#data-loading",
    "href": "Quarto/07_DUPLICATED_CT.html#data-loading",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.2 Data Loading",
    "text": "11.2 Data Loading\nWe load the camera trap setup data (ct) and look for duplicated camera IDs within each structure.\n\n\nCode\n# Read camera trap setup data\nct &lt;- read_sheet(sheet = \"Camera_trap\", na = c(\"NA\", \"na\"))\n\nct |&gt;\n  head(2)\n\n\n$Example1\n# A tibble: 435 × 36\n   Structure_id  Camera_id Camera_position Camera_view Camera_model Camera_setup\n   &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;       \n 1 BC1 (galeria) cam1      Externa         &lt;NA&gt;        Bushnell     &lt;NA&gt;        \n 2 BC1 (galeria) -         &lt;NA&gt;            &lt;NA&gt;        &lt;NA&gt;         &lt;NA&gt;        \n 3 BC1 (galeria) VITA_04   Externa         Abertura    Bushnell     &lt;NA&gt;        \n 4 BC1 (galeria) -         Externa         Abertura    &lt;NA&gt;         &lt;NA&gt;        \n 5 BC1 (galeria) -         Externa         Abertura    &lt;NA&gt;         &lt;NA&gt;        \n 6 BC1 (galeria) -         Externa         Abertura    &lt;NA&gt;         &lt;NA&gt;        \n 7 BC1 (galeria) -         Externa         Abertura    &lt;NA&gt;         &lt;NA&gt;        \n 8 BC1 (galeria) -         Externa         Abertura    &lt;NA&gt;         &lt;NA&gt;        \n 9 BC1 (galeria) VITA_07   Externa         Abertura    Bushnell     &lt;NA&gt;        \n10 BC1 (galeria) VITA_15   Externa         Abertura    Bushnell     &lt;NA&gt;        \n# ℹ 425 more rows\n# ℹ 30 more variables: Camera_vision_photo &lt;chr&gt;, Start_date &lt;dttm&gt;,\n#   Start_time &lt;dttm&gt;, End_date &lt;dttm&gt;, End_time &lt;dttm&gt;, Camera_problem &lt;chr&gt;,\n#   Problem1_from &lt;dttm&gt;, Problem1_to &lt;dttm&gt;, Problem2_from &lt;dttm&gt;,\n#   Problem2_to &lt;dttm&gt;, Problem3_from &lt;dttm&gt;, Problem3_to &lt;dttm&gt;,\n#   Problem4_from &lt;dttm&gt;, Problem4_to &lt;dttm&gt;, Problem5_from &lt;dttm&gt;,\n#   Problem5_to &lt;dttm&gt;, Problem6_from &lt;dttm&gt;, Problem6_to &lt;dttm&gt;, …\n\n$Example2\n# A tibble: 7 × 36\n  Structure_id Camera_id Camera_position Camera_view Camera_model   Camera_setup\n  &lt;chr&gt;        &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;          &lt;chr&gt;       \n1 CE2          cam_CE2   Externa         Abertura    Trail Camera … Secuencia d…\n2 CE3          cam_CE3   Externa         Abertura    Trail Camera … Secuencia d…\n3 CE4          cam_CE4   Externa         Abertura    Trail Camera … Secuencia d…\n4 CE5          cam_CE5   Externa         Abertura    Trail Camera … Secuencia d…\n5 CE6          cam_CE6   Externa         Abertura    &lt;NA&gt;           Secuencia d…\n6 CE7          cam_CE7   Externa         Abertura    Trail Camera … Secuencia d…\n7 CE9          cam_CE9   Externa         Abertura    Trail Camera … Secuencia d…\n# ℹ 30 more variables: Camera_vision_photo &lt;chr&gt;, Start_date &lt;dttm&gt;,\n#   Start_time &lt;dttm&gt;, End_date &lt;dttm&gt;, End_time &lt;dttm&gt;, Camera_problem &lt;chr&gt;,\n#   Problem1_from &lt;dttm&gt;, Problem1_to &lt;dttm&gt;, Problem2_from &lt;dttm&gt;,\n#   Problem2_to &lt;dttm&gt;, Problem3_from &lt;dttm&gt;, Problem3_to &lt;dttm&gt;,\n#   Problem4_from &lt;dttm&gt;, Problem4_to &lt;dttm&gt;, Problem5_from &lt;dttm&gt;,\n#   Problem5_to &lt;dttm&gt;, Problem6_from &lt;dttm&gt;, Problem6_to &lt;dttm&gt;,\n#   Problem7_from &lt;dttm&gt;, Problem7_to &lt;dttm&gt;, Problem8_from &lt;dttm&gt;, …",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#identifying-duplicated-cameras",
    "href": "Quarto/07_DUPLICATED_CT.html#identifying-duplicated-cameras",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.3 Identifying Duplicated Cameras",
    "text": "11.3 Identifying Duplicated Cameras\nWe identify cases where the same camera ID appears more than once within the same structure.\n\n\nCode\nduplicated_cameras &lt;- ct |&gt; \n  purrr::map(~ .x |&gt; \n               dplyr::count(Structure_id, Camera_id) |&gt; \n               dplyr::filter(n &gt; 1)) |&gt; \n  purrr::discard(~ nrow(.x) == 0) |&gt; \n  dplyr::bind_rows(.id = \"Dataset\")\n\nduplicated_cameras |&gt;\n  head()\n\n\n# A tibble: 6 × 4\n  Dataset  Structure_id     Camera_id     n\n  &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt;     &lt;int&gt;\n1 Example1 BC1 (galeria)    -             6\n2 Example1 BC1 (galeria)    VITA_07       2\n3 Example1 BC2 (drenagem)   -             6\n4 Example1 BC2 (drenagem)   VITA_07_1     2\n5 Example1 P10 (amola faca) -            14\n6 Example1 P2 (mauricio)    -             3",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#handling-datasets-with-duplicates",
    "href": "Quarto/07_DUPLICATED_CT.html#handling-datasets-with-duplicates",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.4 Handling Datasets with Duplicates",
    "text": "11.4 Handling Datasets with Duplicates\nWe extract the datasets with duplicated cameras and apply the unique_id function to generate a column Camera_id with the new unique camera IDs. The old ID remains in Camera_id_orig field.\n\n\nCode\ndataset_dup_cameras &lt;- duplicated_cameras |&gt; \n  dplyr::distinct(Dataset) |&gt; \n  dplyr::pull(Dataset)\n\nct_with_dupes &lt;- ct[names(ct) %in% dataset_dup_cameras]\n\nct_uniq &lt;- ct_with_dupes |&gt; \n  purrr::map(~ unique_id(.x))\n\nct_uniq |&gt;\n  head(2)\n\n\n$Example1\n# A tibble: 435 × 38\n   double Structure_id  Camera_id Camera_id_orig Camera_position Camera_view\n    &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;          &lt;chr&gt;           &lt;chr&gt;      \n 1      1 BC1 (galeria) cam1      cam1           Externa         &lt;NA&gt;       \n 2      6 BC1 (galeria) -_A       -              &lt;NA&gt;            &lt;NA&gt;       \n 3      1 BC1 (galeria) VITA_04   VITA_04        Externa         Abertura   \n 4      6 BC1 (galeria) -_B       -              Externa         Abertura   \n 5      6 BC1 (galeria) -_C       -              Externa         Abertura   \n 6      6 BC1 (galeria) -_D       -              Externa         Abertura   \n 7      6 BC1 (galeria) -_E       -              Externa         Abertura   \n 8      6 BC1 (galeria) -_F       -              Externa         Abertura   \n 9      2 BC1 (galeria) VITA_07_A VITA_07        Externa         Abertura   \n10      1 BC1 (galeria) VITA_15   VITA_15        Externa         Abertura   \n# ℹ 425 more rows\n# ℹ 32 more variables: Camera_model &lt;chr&gt;, Camera_setup &lt;chr&gt;,\n#   Camera_vision_photo &lt;chr&gt;, Start_date &lt;dttm&gt;, Start_time &lt;dttm&gt;,\n#   End_date &lt;dttm&gt;, End_time &lt;dttm&gt;, Camera_problem &lt;chr&gt;,\n#   Problem1_from &lt;dttm&gt;, Problem1_to &lt;dttm&gt;, Problem2_from &lt;dttm&gt;,\n#   Problem2_to &lt;dttm&gt;, Problem3_from &lt;dttm&gt;, Problem3_to &lt;dttm&gt;,\n#   Problem4_from &lt;dttm&gt;, Problem4_to &lt;dttm&gt;, Problem5_from &lt;dttm&gt;, …",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#checking-for-remaining-duplicates",
    "href": "Quarto/07_DUPLICATED_CT.html#checking-for-remaining-duplicates",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.5 Checking for Remaining Duplicates",
    "text": "11.5 Checking for Remaining Duplicates\nWe check if any dataset still has more than one camera ID per structure after applying the unique ID function.\n\n\nCode\nct_uniq |&gt; \n  dplyr::bind_rows(.id = \"Dataset\") |&gt; \n  dplyr::count(Dataset, Structure_id, Camera_id) |&gt; \n  dplyr::filter(n &gt; 1) |&gt;\n  head(2)\n\n\n# A tibble: 0 × 4\n# ℹ 4 variables: Dataset &lt;chr&gt;, Structure_id &lt;chr&gt;, Camera_id &lt;chr&gt;, n &lt;int&gt;",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#cross-checking-with-species-records",
    "href": "Quarto/07_DUPLICATED_CT.html#cross-checking-with-species-records",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.6 Cross-checking with Species Records",
    "text": "11.6 Cross-checking with Species Records\nWe load the species records and cross-check them with the corrected camera trap data to ensure records are properly matched.\n\n\nCode\nrec &lt;- read_sheet(sheet = \"Species_records_camera\", na = c(\"NA\", \"na\")) |&gt; \n  purrr::map(\\(x) x |&gt; \n               dttm_update(\n                 date_col = \"Record_date\",\n                 time_col = \"Record_time\"\n               ) |&gt; \n               dplyr::select(-Record_time)\n  ) \n\nrec_with_dupes &lt;- rec[names(rec) %in% dataset_dup_cameras]\n\nrec_with_dupes |&gt; \n  head(2)\n\n\n$Example1\n# A tibble: 3,590 × 6\n   Structure_id   Camera_id Species Record_date         Record_criteria Behavior\n   &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;   &lt;dttm&gt;                        &lt;dbl&gt; &lt;chr&gt;   \n 1 P1 (iguaçu)    cam1      Cavia … 2017-05-09 03:59:00              NA Dentro  \n 2 P3 (varzea)    cam1      Aramid… 2017-05-01 08:37:00              NA Dentro  \n 3 P3 (varzea)    cam1      Leopar… 2017-05-05 21:09:00              NA Dentro  \n 4 BC2 (drenagem) cam2      Didelp… 2018-07-30 04:18:00              NA &lt;NA&gt;    \n 5 BC2 (drenagem) cam2      Didelp… 2018-07-30 20:02:00              NA &lt;NA&gt;    \n 6 BC2 (drenagem) cam2      Didelp… 2018-07-31 00:10:00              NA &lt;NA&gt;    \n 7 BC2 (drenagem) cam2      Didelp… 2018-08-01 01:30:00              NA &lt;NA&gt;    \n 8 BC2 (drenagem) cam2      Didelp… 2018-08-01 03:07:00              NA &lt;NA&gt;    \n 9 BC2 (drenagem) cam2      Didelp… 2018-08-02 00:48:00              NA &lt;NA&gt;    \n10 BC2 (drenagem) cam2      Didelp… 2018-08-02 01:09:00              NA &lt;NA&gt;    \n# ℹ 3,580 more rows",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#output-generation",
    "href": "Quarto/07_DUPLICATED_CT.html#output-generation",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.7 Output Generation",
    "text": "11.7 Output Generation\nFor each dataset with duplicated cameras, we generate Excel files with the corrected camera trap data and the matched records. We also identify records that do not fall within any sampling interval.\n\n\nCode\nrows_with_errors &lt;- list()\n\nfor (dataset in dataset_dup_cameras) {\n  cam &lt;- ct_uniq[[dataset]] |&gt; \n    dplyr::mutate(code = stringr::str_glue(\"S{Structure_id}-C{Camera_id_orig}\"))\n  \n  reg &lt;- rec_with_dupes[[dataset]] |&gt; \n    tibble::rowid_to_column(\"id\") |&gt; \n    dplyr::mutate(code = stringr::str_glue(\"S{Structure_id}-C{Camera_id}\"))\n  \n  intermediate_result &lt;- reg |&gt; \n    dplyr::full_join(cam, by = \"code\", suffix = c(\"_rec\", \"\"), relationship = \"many-to-many\") |&gt; \n    dplyr::mutate(\n      dplyr::across(dplyr::ends_with(\"_time\"), ~ stringr::str_sub(., start = -8, end = -4)),\n      datetime_record = Record_date,\n      datetime_start = lubridate::ymd_hm(paste(\n        as.character(Start_date),\n        tidyr::replace_na(Start_time, \"00:00\")\n      )),\n      datetime_end = lubridate::ymd_hm(paste(\n        as.character(End_date),\n        tidyr::replace_na(End_time, \"00:00\")\n      )),\n      belongs_to = dplyr::if_else(\n        condition = datetime_record %within% c(datetime_start %--% datetime_end),\n        Camera_id,\n        \"nope\"\n      )\n    )\n  \n  intermediate_result |&gt; \n    dplyr::distinct(id, belongs_to, .keep_all = TRUE) |&gt; \n    dplyr::filter(!(dplyr::n() &gt; 1 & belongs_to == \"nope\"), .by = \"id\") |&gt; \n    dplyr::filter(!is.na(id)) |&gt; \n    head()\n  \n  rows_with_errors[[dataset]] &lt;- intermediate_result |&gt; \n    dplyr::filter(all(belongs_to == \"nope\"), .by = \"id\")\n}\n\nrows_with_errors |&gt; \n  dplyr::bind_rows(.id = \"dataset\") |&gt; \n  head()\n\n\n# A tibble: 6 × 51\n  dataset     id Structure_id_rec Camera_id_rec Species      Record_date        \n  &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt;        &lt;dttm&gt;             \n1 Example1     1 P1 (iguaçu)      cam1          Cavia sp.    2017-05-09 03:59:00\n2 Example1     4 BC2 (drenagem)   cam2          Didelphis a… 2018-07-30 04:18:00\n3 Example1     5 BC2 (drenagem)   cam2          Didelphis a… 2018-07-30 20:02:00\n4 Example1     6 BC2 (drenagem)   cam2          Didelphis a… 2018-07-31 00:10:00\n5 Example1     7 BC2 (drenagem)   cam2          Didelphis a… 2018-08-01 01:30:00\n6 Example1     8 BC2 (drenagem)   cam2          Didelphis a… 2018-08-01 03:07:00\n# ℹ 45 more variables: Record_criteria &lt;dbl&gt;, Behavior &lt;chr&gt;, code &lt;glue&gt;,\n#   double &lt;int&gt;, Structure_id &lt;chr&gt;, Camera_id &lt;chr&gt;, Camera_id_orig &lt;chr&gt;,\n#   Camera_position &lt;chr&gt;, Camera_view &lt;chr&gt;, Camera_model &lt;chr&gt;,\n#   Camera_setup &lt;chr&gt;, Camera_vision_photo &lt;chr&gt;, Start_date &lt;dttm&gt;,\n#   Start_time &lt;chr&gt;, End_date &lt;dttm&gt;, End_time &lt;chr&gt;, Camera_problem &lt;chr&gt;,\n#   Problem1_from &lt;dttm&gt;, Problem1_to &lt;dttm&gt;, Problem2_from &lt;dttm&gt;,\n#   Problem2_to &lt;dttm&gt;, Problem3_from &lt;dttm&gt;, Problem3_to &lt;dttm&gt;, …",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  },
  {
    "objectID": "Quarto/07_DUPLICATED_CT.html#results-interpretation",
    "href": "Quarto/07_DUPLICATED_CT.html#results-interpretation",
    "title": "9  Step 7 - Check Duplicated Camera on Structure",
    "section": "11.8 Results Interpretation",
    "text": "11.8 Results Interpretation\nThe output files contain:\n\nCorrected camera trap data with unique camera IDs per structure.\nMatched species records with the corrected camera IDs.\nRecords that do not fall within any camera trap sampling interval.\n\nThis process ensures data consistency and helps identify potential issues with camera deployment or data entry.",
    "crumbs": [
      "Data Quality Checks",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Step 7 - Check Duplicated Camera on Structure</span>"
    ]
  }
]